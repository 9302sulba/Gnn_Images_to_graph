# -*- coding: utf-8 -*-
"""GraphSage_More_tests.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ITNdrVQ3dj7WfgrOJWeXFnbQMQ9_XctF
"""

import pandas as pd
import torch
import igraph as ig
import os
import glob
from torch_geometric.data import Data

# Read the Excel file
df = pd.read_excel('/bsuscratch/sulbhamalviya/New_Test_Folder/No_Time_Data/Data_NoTime.xlsx')

# Calculate the maximum values for normalization
#max_time = df['time'].max()
max_temperature = df['temperature'].max()

# Normalize 'time' and 'temperature' using the maximum values
#df['time'] = df['time'] / max_time
df['temperature'] = df['temperature'] / max_temperature

# Create a dictionary to map filenames to their target values
#file_to_targets = {row["image_name"]: [row["Cr"], row["Co"], row["temperature"], row["time"]] for _, row in df.iterrows()}
file_to_targets = {row["image_name"]: [row["Cr"], row["Co"], row["temperature"]] for _, row in df.iterrows()}

# Define the path to the GraphML files directory and process each GraphML file
graphml_dir_path = "/bsuscratch/sulbhamalviya/New_Test_Folder/No_Time_Data/Graph_Generation/"
data_list = []

for graphml_file_path in glob.glob(os.path.join(graphml_dir_path, "*.graphml")):
    filename = os.path.basename(graphml_file_path)

    if filename in file_to_targets:
        # Load the graph using igraph
        graph = ig.Graph.Read_GraphML(graphml_file_path)

        # Extract node features
        node_features = [[vertex['value']] for vertex in graph.vs]
        edge_indices = [[edge.source, edge.target] for edge in graph.es]
        edge_attrs = [[edge['weight']] for edge in graph.es]

        # Convert to PyTorch tensors
        x = torch.tensor(node_features, dtype=torch.float)
        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()
        edge_attr = torch.tensor(edge_attrs, dtype=torch.float)

        # Get the target values for this graph
        target = torch.tensor(file_to_targets[filename], dtype=torch.float32)

        # Reshape target to [1, 4] (assuming each graph has exactly one target)
        #target_reshaped = target.view(1, 3)
        target_reshaped = target.view(-1, 3)  # Make sure the target has the shape [batch_size, 3]


        # Create PyTorch Geometric Data object
        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=target_reshaped)
        #print("data.x",data.x)
        data_list.append(data)

# Print the number of Data objects created
print(f"Number of Data objects created: {len(data_list)}")

df.head()

from sklearn.model_selection import train_test_split
from torch_geometric.loader import DataLoader

# Split data_list into training and testing sets
train_data, test_data = train_test_split(data_list, test_size=0.2, random_state=42)

# Create DataLoader instances for training and testing data
train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

# Print the number of training and testing samples
print(f"Number of training samples: {len(train_data)}")
print(f"Number of testing samples: {len(test_data)}")

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import SAGEConv, global_mean_pool

# Define the GraphSAGE model with weight initialization
class GraphSAGEModel(nn.Module):
    def __init__(self, in_channels, out_channels, hidden_channels=128):
        super(GraphSAGEModel, self).__init__()
        self.conv1 = SAGEConv(in_channels, hidden_channels, aggr='mean')
        self.conv2 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')
        self.conv3 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')
        self.conv4 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')
        self.conv5 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')
        self.conv6 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')
        self.conv7 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')
        self.conv8 = SAGEConv(hidden_channels, hidden_channels, aggr='mean')
        self.fc1 = nn.Linear(hidden_channels, hidden_channels)
        self.fc2 = nn.Linear(hidden_channels, hidden_channels)
        self.fc3 = nn.Linear(hidden_channels, hidden_channels)
        self.fc4 = nn.Linear(hidden_channels, hidden_channels)
        self.fc5 = nn.Linear(hidden_channels, out_channels)

        # Apply weight initialization
        self.initialize_weights()

    def initialize_weights(self):
        for m in self.modules():
            if isinstance(m, SAGEConv):
                # Apply Xavier initialization for GraphSAGE layers
                torch.nn.init.xavier_uniform_(m.lin_l.weight)
                torch.nn.init.xavier_uniform_(m.lin_r.weight)
                if m.lin_l.bias is not None:
                    torch.nn.init.zeros_(m.lin_l.bias)
            elif isinstance(m, nn.Linear):
                # Apply He initialization for fully connected layers
                torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')
                if m.bias is not None:
                    torch.nn.init.zeros_(m.bias)

    def forward(self, x, edge_index, edge_attr, batch):
        x = F.relu(self.conv1(x, edge_index))
        x = F.relu(self.conv2(x, edge_index))
        x = F.relu(self.conv3(x, edge_index))
        x = F.relu(self.conv4(x, edge_index))
        x = F.relu(self.conv5(x, edge_index))
        x = F.relu(self.conv6(x, edge_index))
        x = F.relu(self.conv7(x, edge_index))
        x = F.relu(self.conv8(x, edge_index))
        x = global_mean_pool(x, batch)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        x = F.relu(self.fc4(x))
        x = self.fc5(x)  # No activation in the final layer
        return x

# Instantiate the model
model = GraphSAGEModel(in_channels=1, out_channels=3)

# Optimizer and loss function
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
criterion = nn.L1Loss()  # Mean Absolute Error

import torch
import torch.nn as nn
import csv

def train(loader):
    model.train()
    total_loss = 0
    train_predictions = []
    train_targets = []

    for batch_idx, batch in enumerate(loader):
        batch.x.requires_grad = True

        optimizer.zero_grad()
        out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)

        loss = criterion(out, batch.y)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)
        optimizer.step()

        total_loss += loss.item()
        train_predictions.append(out)
        train_targets.append(batch.y)

    predictions = torch.cat(train_predictions, dim=0)
    targets = torch.cat(train_targets, dim=0)

    return total_loss / len(loader), predictions, targets


def test(loader):
    model.eval()
    total_loss = 0
    test_predictions = []
    test_targets = []

    with torch.no_grad():
        for batch_idx, batch in enumerate(loader):
            out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)

            loss = criterion(out, batch.y)
            total_loss += loss.item()
            test_predictions.append(out)
            test_targets.append(batch.y)

    predictions = torch.cat(test_predictions, dim=0)
    targets = torch.cat(test_targets, dim=0)

    return total_loss / len(loader), predictions, targets


# Logging and plotting data
train_losses = []
test_losses = []

# Training loop with testing
num_epochs = 1000
for epoch in range(num_epochs):
    # Training
    train_loss, train_predictions, train_targets = train(train_data)
    train_losses.append(train_loss)

    # Extract individual predictions and true values for Cr, Co, and temperature
    pred_Cr_train, pred_Co_train, pred_temperature_train = train_predictions[:, 0], train_predictions[:, 1], train_predictions[:, 2]
    true_Cr_train, true_Co_train, true_temperature_train = train_targets[:, 0], train_targets[:, 1], train_targets[:, 2]

    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}")

    # Testing
    test_loss, test_predictions, test_targets = test(test_data)
    test_losses.append(test_loss)

    pred_Cr_test, pred_Co_test, pred_temperature_test = test_predictions[:, 0], test_predictions[:, 1], test_predictions[:, 2]
    true_Cr_test, true_Co_test, true_temperature_test = test_targets[:, 0], test_targets[:, 1], test_targets[:, 2]

# Save train and test losses to a CSV file
with open('losses.csv', mode='w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(['Epoch', 'Train Loss', 'Test Loss'])
    for epoch in range(num_epochs):
        writer.writerow([epoch+1, train_losses[epoch], test_losses[epoch]])

# Print first 10 values for true and predicted time and temperature
print("First 10 true and predicted values for Time and Temperature:")
for i in range(10):
    #print(f"True Time: {true_time[i].item():.3f}, Pred Time: {pred_time[i].item():.3f}")
    print(f"True Temperature: {true_temperature_train[i].item():.3f}, Pred Temperature: {pred_temperature_train[i].item():.3f}")

print("First 10 true and predicted values for Cr and Co:")
for i in range(10):
    print(f"True Cr: {true_Cr_train[i].item():.3f}, Pred Cr: {pred_Cr_train[i].item():.3f}")
    #print(f"True Co: {true_Co[i].item():.3f}, Pred Co: {pred_Co[i].item():.3f}")

print("First 10 true and predicted values for Cr and Co:")
for i in range(10):
    #print(f"True Cr: {true_Cr[i].item():.3f}, Pred Cr: {pred_Cr[i].item():.3f}")
    print(f"True Co: {true_Co_train[i].item():.3f}, Pred Co: {pred_Co_train[i].item():.3f}")

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error



# Extract individual predictions and true values for Cr, Co, and temperature
pred_Cr_train, pred_Co_train, pred_temperature_train = train_predictions[:, 0], train_predictions[:, 1], train_predictions[:, 2]
true_Cr_train, true_Co_train, true_temperature_train = train_targets[:, 0], train_targets[:, 1], train_targets[:, 2]


def parity_plot(ground_truth, prediction, lims_min, lims_max, plot_name,file_path,r2_value=None):
    plt.figure()

    # Scatter plot of true vs predicted values
    plt.scatter(ground_truth, prediction, label='Data', alpha=0.6)

    # Define the line for perfect prediction
    plt.plot([lims_min, lims_max], [lims_min, lims_max], color='r', linestyle='--', label='Perfect Prediction')

    # Set limits for x and y axes to the range of your data
    plt.xlim(lims_min, lims_max)  # X-axis limit
    plt.ylim(lims_min, lims_max)  # Y-axis limit

    # Add labels, title, legend, and grid
    plt.xlabel('Ground Truth', fontsize=18)
    plt.ylabel('Prediction', fontsize=18)
    plt.title(plot_name, fontsize=20)
    plt.legend()
    plt.grid(True)

    # Calculate MSE
    mse = mean_squared_error(ground_truth, prediction)

    # Add R² and MSE as text to the plot
    plt.text(
        0.05, 0.95,
        f"R-Squared = {r2_value:.3f}\nMSE = {mse:.2E}",
        transform=plt.gca().transAxes,
        fontsize=10,
        verticalalignment='top')

    # Show the plot
    #plt.show()
    plt.savefig(file_path)
    plt.close()


    # Example usage
true_temperature = true_temperature_train.numpy()
pred_temperature = pred_temperature_train.detach().numpy()  # Detach the tensor before calling .numpy()

# Calculate R²
r2_temperature = r2_score(true_temperature, pred_temperature)

# Define plot limits based on your data range
lims_min = min(true_temperature.min(), pred_temperature.min())
lims_max = max(true_temperature.max(), pred_temperature.max())

# Plot name
plot_name_temp = "Parity Plot: True vs. Predicted Temperature"

# Call the function
parity_plot(true_temperature, pred_temperature, lims_min, lims_max, plot_name_temp,'parity_plot_temperature.png',r2_value=r2_temperature)

pred_Cr = pred_Cr_train.detach().numpy()
true_Cr = true_Cr_train.numpy()

# Calculate R²
r2_Cr = r2_score(true_Cr, pred_Cr)

# Plot name for Cr component
plot_name_Cr = "Parity Plot: True vs. Predicted Cr"

# Call the function
parity_plot(true_Cr, pred_Cr, 0, 1, plot_name_Cr,'parity_plot_Cr.png',r2_value=r2_Cr)

pred_Co = pred_Co_train.detach().numpy()
true_Co = true_Co_train.numpy()

# Calculate R²
r2_Co = r2_score(true_Co, pred_Co)

# Plot name for Cr component
plot_name_Co = "Parity Plot: True vs. Predicted Co"

# Call the function
parity_plot(true_Co, pred_Co, 0, 1, plot_name_Co,'parity_plot_Co.png',r2_value=r2_Co)

# Convert to numpy for plotting
#pred_time = pred_time.numpy()
#true_time = true_time.numpy()


# Plot name for Cr component
#plot_name_time = "Parity Plot: True vs. Predicted time"

# Call the function
#parity_plot(true_time, pred_time, lims_min, lims_max, plot_name_time,'parity_plot_time.png')

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

pred_Cr_test, pred_Co_test, pred_temperature_test = test_predictions[:, 0], test_predictions[:, 1], test_predictions[:, 2]
true_Cr_test, true_Co_test, true_temperature_test = test_targets[:, 0], test_targets[:, 1], test_targets[:, 2]


def parity_plot(ground_truth, prediction, lims_min, lims_max, plot_name,file_path,r2_value=None):
    plt.figure()

    # Scatter plot of true vs predicted values
    plt.scatter(ground_truth, prediction, label='Data', alpha=0.6)

    # Define the line for perfect prediction
    plt.plot([lims_min, lims_max], [lims_min, lims_max], color='r', linestyle='--', label='Perfect Prediction')

    # Set limits for x and y axes to the range of your data
    plt.xlim(lims_min, lims_max)  # X-axis limit
    plt.ylim(lims_min, lims_max)  # Y-axis limit

    # Add labels, title, legend, and grid
    plt.xlabel('Ground Truth', fontsize=18)
    plt.ylabel('Prediction', fontsize=18)
    plt.title(plot_name, fontsize=20)
    plt.legend()
    plt.grid(True)

    # Calculate MSE
    mse = mean_squared_error(ground_truth, prediction)

    # Add R² and MSE as text to the plot
    plt.text(
        0.05, 0.95,
        f"R-Squared = {r2_value:.3f}\nMSE = {mse:.2E}",
        transform=plt.gca().transAxes,
        fontsize=10,
        verticalalignment='top')

    # Show the plot
    #plt.show()
    plt.savefig(file_path)
    plt.close()


    # Example usage
true_temperature = true_temperature_test.numpy()
pred_temperature = pred_temperature_test.detach().numpy()  # Detach the tensor before calling .numpy()

# Calculate R²
r2_temperature = r2_score(true_temperature, pred_temperature)

# Define plot limits based on your data range
lims_min = min(true_temperature.min(), pred_temperature.min())
lims_max = max(true_temperature.max(), pred_temperature.max())

# Plot name
plot_name_temp = "Parity Plot: True vs. Predicted Temperature"

# Call the function
parity_plot(true_temperature, pred_temperature, lims_min, lims_max, plot_name_temp,'parity_plot_temperature_test.png',r2_value=r2_temperature)

pred_Cr = pred_Cr_test.detach().numpy()
true_Cr = true_Cr_test.numpy()

# Calculate R²
r2_Cr = r2_score(true_Cr, pred_Cr)

# Plot name for Cr component
plot_name_Cr = "Parity Plot: True vs. Predicted Cr"

# Call the function
parity_plot(true_Cr, pred_Cr, 0, 1, plot_name_Cr,'parity_plot_Cr_test.png',r2_value=r2_Cr)

pred_Co = pred_Co_test.detach().numpy()
true_Co = true_Co_test.numpy()

# Calculate R²
r2_Co = r2_score(true_Co, pred_Co)

# Plot name for Cr component
plot_name_Co = "Parity Plot: True vs. Predicted Co"

# Call the function
parity_plot(true_Co, pred_Co, 0, 1, plot_name_Co,'parity_plot_Co_test.png',r2_value=r2_Co)

# Convert to numpy for plotting
#pred_time = pred_time.numpy()
#true_time = true_time.numpy()


# Plot name for Cr component
#plot_name_time = "Parity Plot: True vs. Predicted time"

# Call the function
#parity_plot(true_time, pred_time, lims_min, lims_max, plot_name_time,'parity_plot_time.png')

import pandas as pd
import matplotlib.pyplot as plt

# Load data from CSV
data = pd.read_csv('losses.csv')

# Create output directory if it doesn't exist
os.makedirs('learning_curves', exist_ok=True)

# Plot train and test losses
plt.figure(figsize=(10, 6))
plt.plot(data['Epoch'], data['Train Loss'], label='Train Loss', color='blue')
plt.plot(data['Epoch'], data['Test Loss'], label='Test Loss', color='red')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Learning Curve')
plt.legend()
plt.grid(True)
# Save the plot to a PDF file
pdf_file_path = 'learning_curves/gnn_learning_curve.pdf'
plt.savefig(pdf_file_path, format='pdf')  # Save as PDF
#plt.show()
plt.close()

# Print first 10 values for true and predicted time and temperature
print("First 10 test true and predicted values for Time and Temperature:")
for i in range(10):
    #print(f"True Time: {true_time[i].item():.3f}, Pred Time: {pred_time[i].item():.3f}")
    print(f"True Temperature: {true_temperature_test[i].item():.3f}, Pred Temperature: {pred_temperature_test[i].item():.3f}")

print("First 10  test true and predicted values for Cr and Co:")
for i in range(10):
    print(f"True Cr: {true_Cr_test[i].item():.3f}, Pred Cr: {pred_Cr_test[i].item():.3f}")
    #print(f"True Co: {true_Co[i].item():.3f}, Pred Co: {pred_Co[i].item():.3f}")

print("First 10 test true and predicted values for Cr and Co:")
for i in range(10):
    #print(f"True Cr: {true_Cr[i].item():.3f}, Pred Cr: {pred_Cr[i].item():.3f}")
    print(f"True Co: {true_Co_test[i].item():.3f}, Pred Co: {pred_Co_test[i].item():.3f}")

import matplotlib.pyplot as plt
import pandas as pd

# Load the data (example assumes you have it in a CSV file or as a DataFrame)
# Replace 'file_path.csv' with your file path
data = pd.read_csv('losses.csv')

# Create output directory if it doesn't exist
os.makedirs('logplot', exist_ok=True)

# Extract values for plotting
epochs = data['Epoch']
train_loss = data['Train Loss']
test_loss = data['Test Loss']

# Create a log plot
plt.figure(figsize=(10, 6))
plt.semilogy(epochs, train_loss, label='Train Loss', color='blue')
plt.semilogy(epochs, test_loss, label='Test Loss', color='red')

# Add labels, title, and legend
plt.xlabel('Epoch', fontsize=14)
plt.ylabel('Loss (Log Scale)', fontsize=14)
plt.title('Training and Testing Loss (Log Scale)', fontsize=16)
plt.legend(fontsize=12)
plt.grid(True, which="both", linestyle='--', linewidth=0.5)

# Save the plot to a PDF file
pdf_file_path = 'logplot/gnn_logplot.pdf'
plt.savefig(pdf_file_path, format='pdf')  # Save as PDF

# Show the plot
#plt.show()
plt.close()

